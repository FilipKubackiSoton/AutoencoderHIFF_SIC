{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Optional\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "sys.path.append('./src')\n",
    "from autoencoder import Autoencoder\n",
    "from SINDY import sindy_library_tf\n",
    "from HIFF import generate_training_sat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] generating trainnig dataset...\n",
      "[INFO] generating testing dataset...\n"
     ]
    }
   ],
   "source": [
    "# generate the trainig set \n",
    "print(\"[INFO] generating trainnig dataset...\")\n",
    "(trainX, trainY) = generate_training_sat(32, 300)\n",
    "\n",
    "# generate the test set \n",
    "print(\"[INFO] generating testing dataset...\")\n",
    "(testX, testY) = generate_training_sat(32,60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'l1': 0.001, 'l2': 0.0, 'dropout': 0.2, 'activation': 'tanh', 'kernel_initializer': <keras.initializers.initializers_v2.RandomNormal object at 0x7f2159c07c88>, 'bias_initializer': <keras.initializers.initializers_v2.Zeros object at 0x7f2159c07d30>}, {'l1': 0.001, 'l2': 0.0, 'dropout': 0.2, 'activation': 'tanh', 'kernel_initializer': <keras.initializers.initializers_v2.RandomNormal object at 0x7f2159c07c88>, 'bias_initializer': <keras.initializers.initializers_v2.Zeros object at 0x7f2159c07d30>}]\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "autoencoder_input (InputLaye [(None, 32)]              0         \n",
      "_________________________________________________________________\n",
      "fucku_0_dropout (Dropout)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "fucku_0 (Dense)              (None, 25)                825       \n",
      "_________________________________________________________________\n",
      "decoder_0 (DenseTranspose)   (None, 32)                857       \n",
      "=================================================================\n",
      "Total params: 857\n",
      "Trainable params: 857\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 5\n",
    "# \"layers_params\" : [{\"l1\": 0.001, \"l2\" : 0.0, \"dropout\" : 0.2}, {\"l1\" : 0.001}],\n",
    "\n",
    "model = Autoencoder([32, 25], ekwargs = {\n",
    "        \"name\" : \"fucku\",\n",
    "        \"layers_params\" : [{\"l1\": 0.001, \"l2\" : 0.0, \"dropout\" : 0.2}, {\"l1\" : 0.001}],\n",
    "        'layers_default_params' : {\n",
    "        'l1' : 0.001, \n",
    "        'l2' : 0.0, \n",
    "        'dropout' : 0.2, \n",
    "        'activation' : \"tanh\",\n",
    "        'kernel_initializer' : tf.keras.initializers.RandomNormal(stddev=0.01),\n",
    "        'bias_initializer' : tf.keras.initializers.Zeros()\n",
    "        },\n",
    "})\n",
    "model.build_graph().summary()\n",
    "model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), \n",
    "        loss=\"mse\")\n",
    "\n",
    "# model.fit(trainY, trainY, \n",
    "# epochs = epochs, \n",
    "# batch_size = batch_size, \n",
    "# verbose = 1)\n",
    "\n",
    "# plt.imshow(model.encoder.weights[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the training dataset.\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((trainY, trainY))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "# Prepare the validation dataset.\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((testY, testY))\n",
    "val_dataset = val_dataset.batch(batch_size)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.01)\n",
    "\n",
    "params = {}\n",
    "params['coefficient_initialization'] = tf.keras.initializers.GlorotUniform()(shape = (2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 0\n",
      "Training loss (for one batch) at step 0: 0.0683\n",
      "Seen so far: 5 samples\n",
      "Training acc over epoch: 0.9334\n",
      "Validation acc: 0.9225\n",
      "Time taken: 1.14s\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss (for one batch) at step 0: 0.0383\n",
      "Seen so far: 5 samples\n",
      "Training acc over epoch: 0.9444\n",
      "Validation acc: 0.9222\n",
      "Time taken: 1.33s\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss (for one batch) at step 0: 0.0233\n",
      "Seen so far: 5 samples\n",
      "Training acc over epoch: 0.9434\n",
      "Validation acc: 0.9392\n",
      "Time taken: 1.35s\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss (for one batch) at step 0: 0.0577\n",
      "Seen so far: 5 samples\n",
      "Training acc over epoch: 0.9447\n",
      "Validation acc: 0.9282\n",
      "Time taken: 1.32s\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss (for one batch) at step 0: 0.0263\n",
      "Seen so far: 5 samples\n",
      "Training acc over epoch: 0.9433\n",
      "Validation acc: 0.9672\n",
      "Time taken: 0.74s\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss (for one batch) at step 0: 0.0706\n",
      "Seen so far: 5 samples\n",
      "Training acc over epoch: 0.9509\n",
      "Validation acc: 0.9861\n",
      "Time taken: 0.86s\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss (for one batch) at step 0: 0.0132\n",
      "Seen so far: 5 samples\n",
      "Training acc over epoch: 0.9498\n",
      "Validation acc: 0.9497\n",
      "Time taken: 0.66s\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss (for one batch) at step 0: 0.0143\n",
      "Seen so far: 5 samples\n",
      "Training acc over epoch: 0.9502\n",
      "Validation acc: 0.9385\n",
      "Time taken: 0.70s\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss (for one batch) at step 0: 0.0415\n",
      "Seen so far: 5 samples\n",
      "Training acc over epoch: 0.9508\n",
      "Validation acc: 0.9578\n",
      "Time taken: 0.51s\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss (for one batch) at step 0: 0.0430\n",
      "Seen so far: 5 samples\n",
      "Training acc over epoch: 0.9488\n",
      "Validation acc: 0.9352\n",
      "Time taken: 0.58s\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss (for one batch) at step 0: 0.0424\n",
      "Seen so far: 5 samples\n",
      "Training acc over epoch: 0.9505\n",
      "Validation acc: 0.9292\n",
      "Time taken: 0.74s\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss (for one batch) at step 0: 0.0145\n",
      "Seen so far: 5 samples\n",
      "Training acc over epoch: 0.9475\n",
      "Validation acc: 0.9333\n",
      "Time taken: 0.63s\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss (for one batch) at step 0: 0.0252\n",
      "Seen so far: 5 samples\n",
      "Training acc over epoch: 0.9506\n",
      "Validation acc: 0.9545\n",
      "Time taken: 0.66s\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss (for one batch) at step 0: 0.0464\n",
      "Seen so far: 5 samples\n",
      "Training acc over epoch: 0.9575\n",
      "Validation acc: 0.9226\n",
      "Time taken: 0.82s\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss (for one batch) at step 0: 0.0111\n",
      "Seen so far: 5 samples\n",
      "Training acc over epoch: 0.9495\n",
      "Validation acc: 0.9258\n",
      "Time taken: 0.76s\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss (for one batch) at step 0: 0.0352\n",
      "Seen so far: 5 samples\n",
      "Training acc over epoch: 0.9559\n",
      "Validation acc: 0.9206\n",
      "Time taken: 0.79s\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss (for one batch) at step 0: 0.0517\n",
      "Seen so far: 5 samples\n",
      "Training acc over epoch: 0.9483\n",
      "Validation acc: 0.9708\n",
      "Time taken: 0.67s\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss (for one batch) at step 0: 0.0320\n",
      "Seen so far: 5 samples\n",
      "Training acc over epoch: 0.9561\n",
      "Validation acc: 0.9268\n",
      "Time taken: 0.63s\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss (for one batch) at step 0: 0.0261\n",
      "Seen so far: 5 samples\n",
      "Training acc over epoch: 0.9503\n",
      "Validation acc: 0.9393\n",
      "Time taken: 0.67s\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss (for one batch) at step 0: 0.0234\n",
      "Seen so far: 5 samples\n",
      "Training acc over epoch: 0.9553\n",
      "Validation acc: 0.9775\n",
      "Time taken: 0.53s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "train_acc_metric = tf.keras.metrics.Mean()\n",
    "val_acc_metric = tf.keras.metrics.Mean()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Iterate over the batches of the dataset.\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(x_batch_train, training=True)\n",
    "            loss_value = loss_fn(y_batch_train, logits)\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "        model.optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "        # Update training metric.\n",
    "        train_acc_metric.update_state(y_batch_train, logits)\n",
    "\n",
    "        # Log every 200 batches.\n",
    "        if step % 200 == 0:\n",
    "            print(\n",
    "                \"Training loss (for one batch) at step %d: %.4f\"\n",
    "                % (step, float(loss_value))\n",
    "            )\n",
    "            print(\"Seen so far: %d samples\" % ((step + 1) * batch_size))\n",
    "\n",
    "    # Display metrics at the end of each epoch.\n",
    "    train_acc = train_acc_metric.result()\n",
    "    print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
    "\n",
    "    # Reset training metrics at the end of each epoch\n",
    "    train_acc_metric.reset_states()\n",
    "\n",
    "    # Run a validation loop at the end of each epoch.\n",
    "    for x_batch_val, y_batch_val in val_dataset:\n",
    "        val_logits = model(x_batch_val, training=False)\n",
    "        # Update val metrics\n",
    "        val_acc_metric.update_state(y_batch_val, val_logits)\n",
    "    val_acc = val_acc_metric.result()\n",
    "    val_acc_metric.reset_states()\n",
    "    print(\"Validation acc: %.4f\" % (float(val_acc),))\n",
    "    print(\"Time taken: %.2fs\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f212af95898>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(model.weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.los"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
