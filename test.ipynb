{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencoder import Autoencoder\n",
    "from SINDY import sindy_library_tf\n",
    "from HIFF import generate_training_sat\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Optional\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] generating trainnig dataset...\n",
      "[INFO] generating testing dataset...\n"
     ]
    }
   ],
   "source": [
    "# generate the trainig set \n",
    "print(\"[INFO] generating trainnig dataset...\")\n",
    "(trainX, trainY) = generate_training_sat(32, 100)\n",
    "\n",
    "# generate the test set \n",
    "print(\"[INFO] generating testing dataset...\")\n",
    "(testX, testY) = generate_training_sat(32,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.initializers.initializers_v2.RandomNormal at 0x7fd08d971240>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = tf.keras.initializers.RandomNormal\n",
    "tmp(stddev=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mean',\n",
       " 'stddev',\n",
       " 'seed',\n",
       " '_random_generator',\n",
       " '__module__',\n",
       " '__doc__',\n",
       " '__init__',\n",
       " '__call__',\n",
       " 'get_config',\n",
       " '_keras_api_names',\n",
       " '_keras_api_names_v1',\n",
       " 'from_config',\n",
       " '__dict__',\n",
       " '__weakref__',\n",
       " '__repr__',\n",
       " '__hash__',\n",
       " '__str__',\n",
       " '__getattribute__',\n",
       " '__setattr__',\n",
       " '__delattr__',\n",
       " '__lt__',\n",
       " '__le__',\n",
       " '__eq__',\n",
       " '__ne__',\n",
       " '__gt__',\n",
       " '__ge__',\n",
       " '__new__',\n",
       " '__reduce_ex__',\n",
       " '__reduce__',\n",
       " '__subclasshook__',\n",
       " '__init_subclass__',\n",
       " '__format__',\n",
       " '__sizeof__',\n",
       " '__dir__',\n",
       " '__class__']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.initializers.RandomNormal(stddev=0.01).__class__\n",
    "tf.keras.initializers.RandomNormal(stddev=0.01).__dir__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tmp = tf.keras.initializers.RandomNormal(stddev=0.01)#.__init__(stddev=0.01)\n",
    "tmp.__class__(**tmp.get_config()) == tmp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean': 0.0, 'stddev': 0.01, 'seed': None}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kwargs default params:  dict_keys(['name'])\n",
      "[{}, {}]\n",
      "{'l1': 0.0, 'l2': 0.0, 'dropout': 0.0, 'activation': 'tanh', 'kernel_initializer': <keras.initializers.initializers_v2.RandomNormal object at 0x7fd08dbdc940>, 'bias_initializer': <keras.initializers.initializers_v2.Zeros object at 0x7fd08dbdc9e8>}\n",
      "end this shit\n",
      "Layer params form encoder: \n",
      "[{'l1': 0.0, 'l2': 0.0, 'dropout': 0.0, 'activation': 'tanh', 'kernel_initializer': <keras.initializers.initializers_v2.RandomNormal object at 0x7fd08dbdc940>, 'bias_initializer': <keras.initializers.initializers_v2.Zeros object at 0x7fd08dbdc9e8>}, {'l1': 0.0, 'l2': 0.0, 'dropout': 0.0, 'activation': 'tanh', 'kernel_initializer': <keras.initializers.initializers_v2.RandomNormal object at 0x7fd08dbdc940>, 'bias_initializer': <keras.initializers.initializers_v2.Zeros object at 0x7fd08dbdc9e8>}]\n",
      "[{'l1': 0.0, 'l2': 0.0, 'dropout': 0.0, 'activation': 'tanh', 'kernel_initializer': <keras.initializers.initializers_v2.RandomNormal object at 0x7fd08dbdc940>, 'bias_initializer': <keras.initializers.initializers_v2.Zeros object at 0x7fd08dbdc9e8>}, {'l1': 0.0, 'l2': 0.0, 'dropout': 0.0, 'activation': 'tanh', 'kernel_initializer': <keras.initializers.initializers_v2.RandomNormal object at 0x7fd08dbdc940>, 'bias_initializer': <keras.initializers.initializers_v2.Zeros object at 0x7fd08dbdc9e8>}]\n",
      "[{'l1': 0.0, 'l2': 0.0, 'dropout': 0.0, 'activation': 'tanh', 'kernel_initializer': <keras.initializers.initializers_v2.GlorotUniform object at 0x7fd08d9c0b38>, 'bias_initializer': <keras.initializers.initializers_v2.Zeros object at 0x7fd08d9c0cc0>}]\n",
      "Model: \"model_47\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "autoencoder_input (InputLaye [(None, 32)]              0         \n",
      "_________________________________________________________________\n",
      "fucku_0 (Dense)              (None, 25)                825       \n",
      "_________________________________________________________________\n",
      "decoder_0 (DenseTranspose)   (None, 32)                857       \n",
      "=================================================================\n",
      "Total params: 857\n",
      "Trainable params: 857\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "34/34 [==============================] - 1s 3ms/step - loss: 0.2838\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.2128\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.1196\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0605\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0313\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0178\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0113\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0074\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0070\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0067\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0061\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0054\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0052\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0049\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0047\n",
      "Epoch 16/20\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0048\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0048\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0046\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0044\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0043\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd08dc8b278>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 3\n",
    "# \"layers_params\" : [{\"l1\": 0.001, \"l2\" : 0.0, \"dropout\" : 0.2}, {\"l1\" : 0.001}],\n",
    "\n",
    "model = Autoencoder([32, 25], ekwargs = {\n",
    "        \"name\" : \"fucku\",\n",
    "        \"layers_params\" : [{\"l1\": 0.001, \"l2\" : 0.0, \"dropout\" : 0.2}, {\"l1\" : 0.001}],\n",
    "        'layers_default_params' : {\n",
    "        'l1' : 0.001, \n",
    "        'l2' : 0.0, \n",
    "        'dropout' : 0.2, \n",
    "        'activation' : \"tanh\",\n",
    "        'kernel_initializer' : tf.keras.initializers.RandomNormal(stddev=0.01),\n",
    "        'bias_initializer' : tf.keras.initializers.Zeros()\n",
    "        },\n",
    "})\n",
    "model.build_graph().summary()\n",
    "model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), \n",
    "        loss=\"mse\")\n",
    "\n",
    "model.fit(trainY, trainY, \n",
    "epochs = epochs, \n",
    "batch_size = batch_size, \n",
    "verbose = 1)\n",
    "\n",
    "plt.imshow(model.encoder.weights[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'fucku_0',\n",
       " 'trainable': True,\n",
       " 'dtype': 'float32',\n",
       " 'units': 25,\n",
       " 'activation': 'tanh',\n",
       " 'use_bias': True,\n",
       " 'kernel_initializer': {'class_name': 'RandomNormal',\n",
       "  'config': {'mean': 0.0, 'stddev': 0.01, 'seed': None}},\n",
       " 'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       " 'kernel_regularizer': {'class_name': 'L1L2',\n",
       "  'config': {'l1': 0.0010000000474974513, 'l2': 0.0}},\n",
       " 'bias_regularizer': None,\n",
       " 'activity_regularizer': None,\n",
       " 'kernel_constraint': None,\n",
       " 'bias_constraint': None}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.encoder.layers[2].__dir__()\n",
    "model.encoder.layers[2].get_config() #_activity_regularizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 32)]              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 25)                825       \n",
      "_________________________________________________________________\n",
      "dense_transpose_2 (DenseTran (None, 32)                857       \n",
      "=================================================================\n",
      "Total params: 857\n",
      "Trainable params: 857\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "34/34 [==============================] - 1s 3ms/step - loss: 0.3060\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.2485\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.2101\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1782\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.1488\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.1363\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1231\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1136\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1015\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0935\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0875\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0784\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0821\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0731\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0745\n",
      "Epoch 16/20\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0733\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0677\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0626\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0570\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0689\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd08de29ba8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMwAAAD5CAYAAABrldrsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAARqElEQVR4nO3db4xc5XXH8e/ZtU1Sg4TdUIsaVCh2Wm2b4FQupSqq8kcgiioZqsaEFxEvUEgkSOtgVCGoFEraiioBGkURFbQobpVgDARhRVYDtaLSvijCUGqM3WLHMsKWsUEQhT8JtndPX8zddm3tc3bOM3f+7Pr3kVY7O3fuvc/e3TN35sy55zF3R0S6MzbsAYjMJwoYkQQFjEiCAkYkQQEjkqCAEUlY1MvKZnYl8E1gHPh7d787evz4mUt90bLlhY0FKxYy3xPLjxRX2f3WivL2KvYVirZXKxpHaX+1nxC0Pf5+jKPtTz+CfR177eCb7n7ObMuqA8bMxoFvA5cDB4HnzGyru+8urbNo2XJ+eeOGwgaDnRUO1r+u/9viKms2F/YD+Hh5VzYVDKM0xsp/OA/O7zYZrDjAgPFF5Y3aicKKwTgsWBb9XQj+LlWC3/nAhltfLS3r5SXZJcA+d9/v7seAzcC6HrYnMvJ6CZiVwGszfj7Y3CeyYPX9Tb+Z3WhmO8xsx+R77/V7dyJ91UvAHALOn/Hzec19J3H3B9x9rbuvHV+6tIfdiQxfLwHzHLDazC40syXA54Ct7QxLZDRVZ8nc/YSZ3Qz8kE5a+SF3f7l6JBVp1ONeTp1EGRcfL+9s7Hj5OaSYMapJAUOYMrJiSi7Y3SDTspWCX6s+u9aPtH5BT5/DuPs2YFtLYxEZefqkXyRBASOSoIARSVDAiCQoYEQSesqSDUqpEPG3t9xSXmeqnGscO15eFhVfFrdXKkIkTnl+9M9fKi575WsfK69YUwQapZWDZeM/Kz+nTi1uN1cdpfujv2d5nWhf6c0BOsOIpChgRBIUMCIJChiRBAWMSMK8yJKVUk1hEeWJYHPR00TFU0hY/DfWh6rH0pXBwTjCHFN0iXLN+CuLIcNMWG2Ba8t0hhFJUMCIJChgRBIUMCIJChiRBAWMSML8SCuXLugO0olRYWDYzXGyIrVZmTqOCixrOnDWFI7OZeqMis6Xgaf+6BvFZZf/YGOr+4o+Phj/WV0uWmcYkQQFjEiCAkYkQQEjkqCAEUlQwIgk9DoD2QHgHWASOOHua9sYVNf6UcFakSEOq4Qri5XDiuoRaftaFIzv52EP32CbNX/PYJ3xD+r+Qdr4HOZT7v5mC9sRGXl6SSaS0GvAOPCUmT1vZje2MSCRUdbrS7LL3P2Qmf0S8LSZ/be7PzPzAU0g3QgwvmxZj7sTGa6ezjDufqj5fhR4gs5Esac+RjOQyYJRHTBmttTMzpq+DVwB7GprYCKjqJeXZCuAJ8xsejvfc/d/rt5aOFd84f4obRhUo5a2N5dSqjdsFRs06oh+5x9f+3fFZase/tLs++pDKt2CtrrF8QdPw+se+0p5c1HGueW08rGz60q7e5mybz9wce36IvOR0soiCQoYkQQFjEiCAkYkQQEjkjA6TTAqKnCjmcQ8aIIRNboI08AFkx8upyijtGxUkfz25Pvl9QbYS7hqFq/gEA60CrsPVd06w4gkKGBEEhQwIgkKGJEEBYxIwmCzZEa5IK5mHvmoRWswm1XYRjZ4CrHJwjCORT1r6y74X/voLeX1itsLllVeLz+1OFitcDwiUWZz1V07i8v23lVuq1v8m/Wh54POMCIJChiRBAWMSIICRiRBASOSoIARSRid4stAscgvKAwMiwajGciia9hLwwiO4tiJqBIxvavRUpOaDT8+aPeARL0Woo8Wwm3WDkbkdKSAEUlQwIgkKGBEEhQwIgkKGJGEOdPKZvYQ8IfAUXf/zea+5cAjwAXAAWC9u789596cqlRqqSo2Sg+v/rMXisteuecT+UFAMY0aprCjYuWgt8BU0CdgrDB7VnVSNmoVW1GRHFY/n1He2d67Pl5cFvYxKGxyaklUzR5sL9DNGeY7wJWn3HcbsN3dVwPbm59FFrw5A6aZ7+WtU+5eB2xqbm8Crm53WCKjqfY9zAp3P9zcfp1OJ3+RBa/nN/3uHr4zMbMbzWyHme2YfO+9XncnMlS1AXPEzM4FaL4fLT1QM5DJQlIbMFuB65vb1wNPtjMckdHWTVr5YeCTwEfM7CDwVeBuYIuZ3QC8Cqzv5yBLacqooQJj5WUWVLGGTyEtVxeHbWmjdrYDbBVbrBSn/ZSzBQ1DPGp4UlqnYvK0ucwZMO5+XWHRZyr3KTJv6ZN+kQQFjEiCAkYkQQEjkqCAEUmYF00wVt3y7Kz377vvd4rr7PvroCK5tgdxm+sQ92SOZlBrvZdwsF44xlJavB/NPWrGH6Wig7R9RGcYkQQFjEiCAkYkQQEjkqCAEUlQwIgkjE5aOcryWUVcV06VFyptsjJlG1UCh+OvqNydD6aCpiajQmcYkQQFjEiCAkYkQQEjkqCAEUkYnSxZkCDZf/clsy+YiqoGy8vGC61WIZ5NLLwGvyRIdoUFluG17/lh1BZmRu14i5urbJ3bdv+AXdd8q7jsY1v+JL9BdIYRSVHAiCQoYEQSFDAiCQoYkQQFjEhC7QxkdwJfAN5oHna7u2/r1yDL12wHq0Sp17DQsyKNGhVYButFKdvSLGNQvqY/HEdtb9S2+x/UpssrxjFu7ffUrZ2BDOA+d1/TfPUvWERGSO0MZCKnpV7ew9xsZjvN7CEzW9baiERGWG3A3A9cBKwBDgP3lB6oGchkIakKGHc/4u6T7j4FPAgUir00A5ksLFUBMz1dX+MaYFc7wxEZbbUzkH3SzNbQSegdAL7YvyHC5IdmzxtGbUyjHGux1Sp1s2BF24tSr9FMaFHl7qqv/Mes9++799JgIHWimb9K4w9T2GGevbsxdWvikS+XF1ZmnGtnIPuHut2JzG/6pF8kQQEjkqCAEUlQwIgkKGBEEkanCUagVMU6tSSo9j1e3l7UkrSqwUQg2t7U4mjFYIyLZv+zVVcrD7BDa9TMIkz31/xulen+iM4wIgkKGJEEBYxIggJGJEEBI5KggBFJmBdp5VIKMKpWjntZlBc+d+29xWVrH7sl2miaLynnnMffLz+X7f362lnvb7uJxJzrtS1KKwd/62KP6trjEdAZRiRBASOSoIARSVDAiCQoYEQS5kWWrNRS1SaDzEmQBYmKHhdb/jmkZnYsADseZPmi363UW2CQGa1alWOMCmbb3ldEZxiRBAWMSIICRiRBASOSoIARSVDAiCR00yr2fOAfgRV0yvQecPdvmtly4BHgAjrtYte7+9v9GGSpyDKawStKKUbX+1/86IbuBjXDts8WJy/gqkc3llcMU98VM6EFxYZR69lwm0E725Klh8rPw++d13LThFp9vKb/BLDR3SeAS4GbzGwCuA3Y7u6rge3NzyILWjczkB129xea2+8Ae4CVwDpgU/OwTcDVfRqjyMhIvYcxswuATwDPAivc/XCz6HU6L9lEFrSuA8bMzgQeBza4+09nLnN3p/CqUDOQyULSVcCY2WI6wfJdd/9+c/eR6YmVmu9HZ1tXM5DJQjJnwJiZ0ZkPZo+7z7x+dytwfXP7euDJ9ocnMlq6qVb+PeDzwEtm9mJz3+3A3cAWM7sBeBVY35cRQjn9GmQ8o8pdizKlFde+jwc5ytp0btU1+LXVuS23kQ2PfdQqtvZYFTfY8vbobgayf6d8SD/T7nBERps+6RdJUMCIJChgRBIUMCIJChiRhPnRBKMU1lGxcjRjVfA0MfZBOSdaqiC+4vFbyxsMLHq3PJBodrVS+vW59X1ocxs9pRYKj99fWVeRHFZbtz2DmlrFivSfAkYkQQEjkqCAEUlQwIgkKGBEEuZFWrlKP2bVKqxXmw6dqjz6pW3+wljQNLryeISVx8Ema8YRNtwIGp4Msqe0zjAiCQoYkQQFjEiCAkYkQQEjkjA6WbKK4rpwlq4gq/Jrf7GnuOyVOyaCgcwuynaNnQhWDCpEwwLRwjYnHvlysLMBijJhwd8sao8b/T1L2bWoR0CU2YzoDCOSoIARSVDAiCQoYEQSFDAiCQoYkYReZiC7E/gC8Ebz0NvdfVtfRlnKRI7V9QL1Y+UpyMJWpoWjVVt8GfYdGA/SqFMDrDaMBlldxVoQPH1X/c7R/0flMezmc5jpGcheMLOzgOfN7Olm2X3u/o2qPYvMQ930Vj4MHG5uv2Nm0zOQiZx2epmBDOBmM9tpZg+Z2bK2BycyanqZgex+4CJgDZ0z0KxTCWsGMllIqmcgc/cj7j7p7lPAg8Als62rGchkIamegWx6ur7GNcCu9ocnMlp6mYHsOjNbQyfVfAD4Yk8jqcgQR1XCUXp479c+Xh5GmOst3B887exe/63isokt5eriseNBJXbFjGzh8a29zr64UrCrqCK5cuayYq+F4BjW6mUGsv585iIywvRJv0iCAkYkQQEjkqCAEUlQwIgkjE4TjEgprCurUaeihgpBk4ZiM46g0cUZVm7fGjW6qGrtWle8HWt55q8o1evBrGthRXjpOPahqFtnGJEEBYxIggJGJEEBI5KggBFJUMCIJMyLtPLYz0u9c4MUZVAVGz5NRFWxpX0FPXxXPfyl8jCiwuhojC3PhBb56B07i8te+atC1XdU/Rz2XS4vKzUgifZXlYqeg84wIgkKGJEEBYxIggJGJEEBI5KggBFJmBdp5WLaNpryLkqjBunGqOlDqd9xbTp3LNhXNH1dSV86Lo8HOfOCfqS3w5RzTfV2ZWW3zjAiCQoYkQQFjEiCAkYkQQEjktDNDGQfAp4Bzmge/5i7f9XMLgQ2A78IPA983t2PxRuj6nr0qcK13mH70MDYsXbzSf2YZWy8UHAK5eNRm4Fa/G55xb13/kZ6e1Fho03V9VP4t2u/Xlx22WO3psdRm1Ls5gzzAfBpd7+YztQWV5rZpcDf0JmBbBXwNnBD3RBE5o85A8Y73m1+XNx8OfBp4LHm/k3A1f0YoMgo6XZ+mPGmc/9R4Gngx8BP3H26wdBBNI2fnAa6Cphm4qQ1wHl0Jk769W53cNIMZO9qBjKZ31JZMnf/CfAj4HeBs81sOmlwHnCosM7/z0B2pmYgk/mtmxnIzjGzs5vbHwYuB/bQCZw/bh52PfBkn8YoMjK6Kb48F9hkZuN0AmyLu//AzHYDm83sL4H/pDOtX8ypay9aSB9HRX7xOCrzwC3vKnq6Cn+3llvFRunX2lR1zQajNPuo6GYGsp10pho/9f79FCaCFVmo9Em/SIICRiRBASOSoIARSVDAiCSY++BSeWb2BvBq8+NHgDcHtvMyjeNkGgf8irufM9uCgQbMSTs22+Hua4eyc41D46ikl2QiCQoYkYRhBswDQ9z3TBrHyTSOwNDew4jMR3pJJpIwlIAxsyvN7H/MbJ+Z3TaMMTTjOGBmL5nZi2a2Y4D7fcjMjprZrhn3LTezp81sb/N92ZDGcaeZHWqOyYtmdtUAxnG+mf3IzHab2ctm9qfN/QM/JnMZeMA0lwl8G/gDYAK4zswmBj2OGT7l7msGnML8DnDlKffdBmx399XA9ubnYYwDOs1N1jRf2wYwjhPARnefAC4Fbmr+J4ZxTELDOMNcAuxz9/1NW6bNwLohjGNo3P0Z4K1T7l5Hp5kIDKipSGEcA+fuh939heb2O3QuUFzJEI7JXIYRMCuB12b8PMwGGg48ZWbPm9mNQxrDtBXufri5/TqwYohjudnMdjYv2Qb6MsjMLqBz/dWzjNYxAfSm/zJ3/y06Lw9vMrPfH/aAoNPaiurrJ3t2P3ARnR50h4F7BrVjMzsTeBzY4O4/nblsyMfk/wwjYA4B58/4udhAo9/c/VDz/SjwBMO9gvSImZ0L0Hw/OoxBuPuRpkvQFPAgAzomZraYTrB8192/39w9EsdkpmEEzHPAajO70MyWAJ8Dtg56EGa21MzOmr4NXAHsitfqq610monAEJuKTP+DNq5hAMfEzIxOT4g97n7vjEUjcUxO4u4D/wKuAl6h0xDwjiGN4VeB/2q+Xh7kOICH6bzcOU7nPdwNdHpUbwf2Av8CLB/SOP4JeAnYSecf9twBjOMyOi+3dgIvNl9XDeOYzPWlT/pFEk73N/0iKQoYkQQFjEiCAkYkQQEjkqCAEUlQwIgkKGBEEv4X+KI5M+T00pkAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from shallowNet.shallowNet import shallowNet\n",
    "model2 = shallowNet.build()\n",
    "model2.fit(\n",
    "    trainY, trainY,\n",
    "    epochs = epochs, \n",
    "    batch_size = batch_size,\n",
    ")\n",
    "plt.imshow(model2.weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd08de8bc88>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def suplement_layers_params([32,25], [{\"l1\": 0.001, \"l2\" : 0.0, \"dropout\" : 0.2}, {\"l1\" : 0.001}], ) -> dict:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \"layers_params\" : [{\"l1\": 0.001, \"l2\" : 0.0, \"dropout\" : 0.2}, {\"l1\" : 0.001}],\n",
    "        'layers_default_params' : {\n",
    "        'l1' : 0.001, \n",
    "        'l2' : 0.0, \n",
    "        'dropout' : 0.2, \n",
    "        'activation' : \"tanh\",\n",
    "        'kernel_initializer' : tf.keras.initializers.RandomNormal(stddev=0.01),\n",
    "        'bias_initializer' : tf.keras.initializers.Zeros()\n",
    "        },"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "from typing import List, Optional\n",
    "\n",
    "def suplement_layers_params(architecture : List[int], layers_params : List[dict], layers_default_params : dict) -> dict:\n",
    "    # add empty dicionaries to layers_params to corecponds to the encoding_layers_size size\n",
    "    for _ in range(len(architecture) - len(layers_params)):\n",
    "        layers_params.append({})\n",
    "    return [{**layers_default_params, **x} for x in layers_params]\n",
    "\n",
    "class DenseTranspose(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Dense transpose layer from dense layer\n",
    "    \"\"\"\n",
    "    def __init__(self, dense, activation = None, **kwargs):\n",
    "        self.dense = dense \n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "        super(DenseTranspose, self).__init__(**kwargs)\n",
    "    def build(self, batch_input_shape):\n",
    "        self.b = self.add_weight(name= \"bias\", shape = [ self.dense.input_shape[-1]], initializer = \"zeros\")\n",
    "        self.w = self.dense.weights[0]\n",
    "        super().build(batch_input_shape)\n",
    "        \n",
    "        \n",
    "    def call(self, inputs):\n",
    "        z = tf.linalg.matmul(inputs, self.w, transpose_b = True)\n",
    "        return self.activation(z + self.b)\n",
    "    \n",
    "    def get_weights(self):\n",
    "        return {\"w\": np.shape(tf.transpose(self.w))}    \n",
    "    @property \n",
    "    def weights_transpose(self):\n",
    "        return tf.transpose(self.dense.weights[0])\n",
    "\n",
    "\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Encoder\n",
    "\n",
    "    isFirstInputLayer - use input dimension only in Input Layer\n",
    "    Kernel and bias are initialize by fresh instances of objects\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "    widths : List[int] = [32,24], \n",
    "    isFirstInputLayer : Optional[bool] = True,\n",
    "    layers_params : Optional[List[dict]] = [{}],\n",
    "    layers_default_params : dict = {\n",
    "        'l1' : 0.001, \n",
    "        'l2' : 0.0, \n",
    "        'dropout' : 0.2, \n",
    "        'activation' : \"tanh\",\n",
    "        'kernel_initializer' : tf.keras.initializers.GlorotUniform(),\n",
    "        'bias_initializer' : tf.keras.initializers.Zeros()\n",
    "        },\n",
    "    **kwargs):\n",
    "        super(Encoder, self).__init__(**kwargs)\n",
    "        self.latent_dim = widths[-1]\n",
    "        self.input_dim = widths[0]\n",
    "        self.layers = []\n",
    "        \n",
    "        if not (\"name\" in kwargs.keys()):\n",
    "            kwargs[\"name\"] = \"encoder\"\n",
    "\n",
    "        \n",
    "        print(\"kwargs default params: \", kwargs.keys())\n",
    "        print(layers_params)\n",
    "        print(layers_default_params)\n",
    "        print(\"end this shit\")\n",
    "        layers_params = suplement_layers_params(widths, layers_params, layers_default_params)\n",
    "        print(\"Layer params form encoder: \\n{}\".format(layers_params))\n",
    "        for (layer_index, layer_dim), layer_params_ in zip(\n",
    "            enumerate(widths[1:] if isFirstInputLayer else widths), \n",
    "            layers_params):\n",
    "\n",
    "            if layer_params_[\"dropout\"] > 0.0:\n",
    "                self.layers.append(Dropout(\n",
    "                    layer_params_[\"dropout\"],\n",
    "                    name = kwargs[\"name\"] + \"_{}_dropout\".format(layer_index)\n",
    "                    ))\n",
    "            # construct encoder layer \n",
    "            self.layers.append(Dense(\n",
    "                    units = layer_dim,\n",
    "                    activation= layer_params_[\"activation\"],\n",
    "                    kernel_initializer= layer_params_[\"kernel_initializer\"].__class__(**layer_params_[\"kernel_initializer\"].get_config()),\n",
    "                    bias_initializer= layer_params_[\"bias_initializer\"].__class__(**layer_params_[\"bias_initializer\"].get_config()),\n",
    "                    kernel_regularizer = tf.keras.regularizers.L1L2(\n",
    "                        l1=layer_params_[\"l1\"], \n",
    "                        l2=layer_params_[\"l2\"]),\n",
    "                    name = kwargs[\"name\"] + \"_{}\".format(layer_index)))\n",
    "        \n",
    "        print(layers_params)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = inputs\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    def build_graph(self):\n",
    "        x = Input(shape=(self.input_dim, ), name = 'encoder_input')\n",
    "        return tf.keras.Model(inputs = [x], outputs = self.call(x))\n",
    "\n",
    "\n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Decoder\n",
    "\n",
    "    isTranspose - use transposed layers from encoder. If False create fresh layers of the same size of encoder\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    Add decoder documentation.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "    encoder : Encoder, \n",
    "    isTranspose : Optional[bool] = True,  \n",
    "    layers_params : Optional[List[dict]] = [],\n",
    "    layers_default_params : dict = {\n",
    "        'l1' : 0.0, \n",
    "        'l2' : 0.0,\n",
    "        'dropout' : 0.0, \n",
    "        'activation' : \"tanh\",\n",
    "        'kernel_initializer' : tf.keras.initializers.GlorotUniform(),\n",
    "        'bias_initializer' : tf.keras.initializers.Zeros()\n",
    "        }, \n",
    "    **kwargs):\n",
    "\n",
    "        super(Decoder, self).__init__(**kwargs)\n",
    "        self.input_dim = encoder.weights[0].shape[-1]\n",
    "        self.output_dim = encoder.weights[-1].shape[-1]\n",
    "        self.layers = []\n",
    "\n",
    "        if not (\"name\" in kwargs.keys()):\n",
    "            kwargs[\"name\"] = \"decoder\"\n",
    "\n",
    "        layers_params = suplement_layers_params([x for x in encoder.layers[1:][::-1] if type(x) == Dense], layers_params, layers_default_params)\n",
    "\n",
    "        if isTranspose:\n",
    "            for layer_index, layer in enumerate([x for x in encoder.layers[1:][::-1] if type(x) == Dense]):\n",
    "                self.layers.append(\n",
    "                    DenseTranspose(\n",
    "                        dense = layer,\n",
    "                        name = kwargs[\"name\"] + \"_{}\".format(layer_index)\n",
    "                        )\n",
    "                    )\n",
    "        else:        \n",
    "            for (layer_index, layer_dim), layer_params_ in zip(\n",
    "                enumerate([x.input_shape[-1] for x in encoder.layers][1:][::-1]), \n",
    "                layers_params):\n",
    "                \n",
    "                if layer_params_[\"dropout\"] > 0.0:\n",
    "                    self.layers.append(Dropout(\n",
    "                        layer_params_[\"dropout\"],\n",
    "                        name = kwargs[\"name\"] + \"_{}_dropout\".format(layer_index)\n",
    "                        ))\n",
    "\n",
    "                self.layers.append(Dense(\n",
    "                    units = layer_dim,\n",
    "                    activation= layer_params_[\"activation\"],\n",
    "                    kernel_initializer= layer_params_[\"kernel_initializer\"].__class__(**layer_params_[\"kernel_initializer\"].get_config()),\n",
    "                    bias_initializer= layer_params_[\"bias_initializer\"].__class__(**layer_params_[\"bias_initializer\"].get_config()),\n",
    "                    kernel_regularizer = tf.keras.regularizers.L1L2(\n",
    "                        l1=layer_params_[\"l1\"], \n",
    "                        l2=layer_params_[\"l2\"]),\n",
    "                    name = kwargs[\"name\"] + \"_{}\".format(layer_index)))\n",
    "    \n",
    "        print(layers_params)\n",
    "    \"\"\"\n",
    "    Add privileged training: training = None \n",
    "    \"\"\"\n",
    "    def call(self, inputs):\n",
    "        x = inputs\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    def build_graph(self):\n",
    "        x = Input(shape=(self.output_dim, ), name = 'decoder_input')\n",
    "        return tf.keras.Model(inputs = [x], outputs = self.call(x))\n",
    "\n",
    "    \"\"\"\n",
    "    Overtide this method to enable serialization \n",
    "    \"\"\"\n",
    "    def get_config(self):\n",
    "        pass\n",
    "\n",
    "class Autoencoder(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    Autoencoder\n",
    "    Stack both encoder and decoder\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "    widths : List[int] = [32,28,25], \n",
    "    name : Optional[str] = \"autoencoder\", \n",
    "    ekwargs : Optional[dict] = {}, \n",
    "    dkwargs : Optional[dict] = {}, \n",
    "    **kwargs):\n",
    "        if not (\"name\" in kwargs.keys()):\n",
    "            kwargs[\"name\"] = \"autoencoder\"\n",
    "\n",
    "        super(Autoencoder, self).__init__(**kwargs)\n",
    "        self.input_dim = widths[0]\n",
    "        self.latent_dim = widths[-1]\n",
    "        self.encoder = Encoder(widths, **ekwargs).build_graph()\n",
    "        self.decoder = Decoder(self.encoder, **dkwargs).build_graph()\n",
    "    \n",
    "    def call(self, input):        \n",
    "        x = self.encoder.layers[1](input)\n",
    "        for layer in self.encoder.layers[2:] + self.decoder.layers[1:]:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "        \n",
    "    \n",
    "    def compile(self, **kwargs):\n",
    "        super(Autoencoder, self).compile(**kwargs)\n",
    "\n",
    "    def build_graph(self,):\n",
    "        x = Input(shape=(self.input_dim, ), name = 'autoencoder_input')\n",
    "        return tf.keras.Model(inputs = [x], outputs = self.call(x))\n",
    "\n",
    "    def encode(self, input):\n",
    "        return self.encoder(input)\n",
    "    \n",
    "    def decode(self, input):\n",
    "        return self.decoder(input)\n",
    "\n",
    "    def get_input_dim(self) -> int:\n",
    "        return self.input_dim\n",
    "    \n",
    "    def get_latent_dim(self) -> int:\n",
    "        return self.latent_dim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
